% Chapter Template

\chapter{Introduction} % Main chapter title

\label{Introduction} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

Automatic speech recognition (ASR) is the ability of a machine to recognize language from human speech and convert it into written text~\cite{wang_2021}. Due to the endless number of possible and practical applications of ASR technology in our developing world, major corporations still aspire to develop an accurate yet optimized speech recognition system for their products and services. For instance, Baidu spent a total of \$4.7 billion dollars on research and development~\cite{thomala_2022}, of which a large portion headed into developing their voice assistant, DuerOS. Hence, the implementation of ASR can improve the ergonomics of any task that requires human interaction, such as personal assistants, smart healthcare and household appliances, and media transcription to support people with disabilities, hearing impairments, or language barriers. However, such a task is difficult due to the sheer complexity of any spoken language, as well as the varying and unpredictable nature of different people and their speaking habits. Even big-name companies such as Alphabet, Microsoft, and Apple, who pride themselves in their sophisticated multi-million dollar speech recognition systems, have been countlessly ridiculed for misinterpretations in their voice recognition products even today.
\par
The field of ASR is rather new compared to other fields in computer science as significant developments in ASR only began in the 50s, with the innovation of Bell’s Audrey and IBM’s Shoebox~\cite{sonix_authors_2022,summa_linguae_authors_2021}. These systems fell into a category of ASR systems that recognized individual words to an isolated vocabulary using manually set parameters for phoneme recognition~\cite{summa_linguae_authors_2021}. By the end of the decade, ASR technology could distinguish words with a maximum of four vowels and nine consonants and by the 70s, systems could recognize up to 1000 words, which is around the vocabulary of a three-year-old toddler~\cite{sonix_authors_2022}. It was not until the late 90s that researchers transitioned outwards of phoneme detection to Hidden Markov Models (HMM) and focused on natural language processing~\cite{summa_linguae_authors_2021}. Deep learning concepts and technologies emerged and were investigated to be a reliable alternative to HMMs, to the extent to which it is prominently used today.
\par
However, a plausible deep learning system that can recognize continuous speech within a low margin of error is very strenuous to build. A well-designed system can consist of multiple complex layers that can be very complicated to integrate into one another. Nowadays, large tech companies boast an accuracy of almost 95\%, which is still fairly low in the context of sophisticated deep-learning models~\cite{sonix_authors_2022}. One of these layers is commonly a feature extraction layer that can optimize an input waveform and isolates specific qualities of the inputted speech data~\cite{janse_magre_kurzekar_deshmukh_2014,ajibola_alim_khair_alang_rashid_2018}. Modern speech recognition models widely use algorithms such as Mel-Frequency Cepstrum Coefficients (MFCCs) as a pre-processing layer. Yet, MFCCs often have shortcomings when processing audio signals, such as being excessively sensitive to noise and imperfections in waveforms~\cite{janse_magre_kurzekar_deshmukh_2014}.
\par
This report aims to investigate the extent to which Mel-Frequency Cepstrum Coefficients outperform other feature extraction methods in automatic speech recognition systems. The performances of short-term Fourier transform spectrograms, MFCCs, Mel spectrograms, and discrete wavelet transforms (DWTs) will be assessed against each other by being processed through identical ASR neural network architectures. From this investigation, the effectiveness and limitations of different speech feature extraction methods will be better understood and advise forthcoming decisions in ASR neural networks.